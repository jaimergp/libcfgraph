{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.22.0",
  "conda_private": false,
  "conda_version": "4.13.0",
  "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.\n",
  "dev_url": "https://github.com/huggingface/datasets",
  "doc_url": "https://huggingface.co/docs/datasets/",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "oblute",
    "Tata17",
    "thewchan",
    "mxr-conda"
   ]
  },
  "home": "https://github.com/huggingface/datasets",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "license_file": "LICENSE",
  "root_pkgs": [
   "chardet 5.0.0 py39hf3d152e_0",
   "lzo 2.10 h516909a_1000",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "tk 8.6.12 h27826a3_0",
   "ripgrep 13.0.0 h2f28480_2",
   "libuuid 2.32.1 h7f98852_1000",
   "libxml2 2.9.14 h22db469_3",
   "reproc-cpp 14.2.3 h9c3ff4c_0",
   "psutil 5.9.1 py39hb9d737c_0",
   "c-ares 1.18.1 h7f98852_0",
   "prompt_toolkit 3.0.30 hd8ed1ab_0",
   "wcwidth 0.2.5 pyh9f0ad1d_2",
   "py-lief 0.11.5 py39he80948d_1",
   "glob2 0.7 py_0",
   "nbformat 5.4.0 pyhd8ed1ab_0",
   "dataclasses 0.8 pyhc8e2a94_3",
   "pytz 2022.1 pyhd8ed1ab_0",
   "_libgcc_mutex 0.1 conda_forge",
   "charset-normalizer 2.1.0 pyhd8ed1ab_0",
   "tini 0.19.0 h7f98852_0",
   "idna 3.3 pyhd8ed1ab_0",
   "libedit 3.1.20191231 he28a2e2_2",
   "pyrsistent 0.18.1 py39hb9d737c_1",
   "conda 4.13.0 py39hf3d152e_1",
   "libssh2 1.10.0 ha56f1ee_2",
   "libsolv 0.7.22 h6239696_0",
   "anaconda-client 1.8.0 pyhd8ed1ab_0",
   "prompt-toolkit 3.0.30 pyha770c72_0",
   "jinja2 3.1.2 pyhd8ed1ab_1",
   "pkginfo 1.8.3 pyhd8ed1ab_0",
   "patchelf 0.15.0 h58526e2_0",
   "pybind11-abi 4 hd8ed1ab_3",
   "traitlets 5.3.0 pyhd8ed1ab_0",
   "gettext 0.19.8.1 h73d1719_1008",
   "libzlib 1.2.12 h166bdaf_2",
   "libev 4.33 h516909a_1",
   "commonmark 0.9.1 py_0",
   "pygments 2.12.0 pyhd8ed1ab_0",
   "clyent 1.2.2 py_1",
   "libnghttp2 1.47.0 h727a467_0",
   "sniffio 1.2.0 py39hf3d152e_3",
   "pycosat 0.6.3 py39hb9d737c_1010",
   "krb5 1.19.3 h3790be6_0",
   "future 0.18.2 py39hf3d152e_5",
   "importlib-metadata 4.11.4 py39hf3d152e_0",
   "su-exec 0.2 h516909a_1002",
   "beautifulsoup4 4.11.1 pyha770c72_0",
   "conda-package-handling 1.8.1 py39hb9d737c_1",
   "mamba 0.24.0 py39hfa8f2c8_1",
   "attrs 21.4.0 pyhd8ed1ab_0",
   "lz4-c 1.9.3 h9c3ff4c_1",
   "jupyter_core 4.11.1 py39hf3d152e_0",
   "libnsl 2.0.0 h7f98852_0",
   "libgomp 12.1.0 h8d9b700_16",
   "pyopenssl 22.0.0 pyhd8ed1ab_0",
   "ncurses 6.3 h27087fc_1",
   "ld_impl_linux-64 2.36.1 hea4e1c9_2",
   "reproc 14.2.3 h7f98852_0",
   "libiconv 1.16 h516909a_0",
   "xz 5.2.5 h516909a_1",
   "bzip2 1.0.8 h7f98852_4",
   "readline 8.1.2 h0f457ee_0",
   "icu 70.1 h27087fc_0",
   "python-libarchive-c 4.0 py39hf3d152e_1",
   "libffi 3.4.2 h7f98852_5",
   "python-fastjsonschema 2.16.1 pyhd8ed1ab_0",
   "zstd 1.5.2 h8a70e8d_2",
   "backports 1.0 py_2",
   "pcre2 10.37 h032f7d1_0",
   "python_abi 3.9 2_cp39",
   "importlib_resources 5.8.0 pyhd8ed1ab_0",
   "libarchive 3.5.2 hb890918_3",
   "liblief 0.11.5 h9c3ff4c_1",
   "tzdata 2022a h191b570_0",
   "filelock 3.7.1 pyhd8ed1ab_0",
   "cryptography 37.0.4 py39hd97740a_0",
   "cffi 1.15.1 py39he91dace_0",
   "pyyaml 6.0 py39hb9d737c_4",
   "libmamba 0.24.0 hd8a31e3_1",
   "zipp 3.8.0 pyhd8ed1ab_0",
   "anyio 3.6.1 py39hf3d152e_0",
   "libgcc-ng 12.1.0 h8d9b700_16",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "brotlipy 0.7.0 py39hb9d737c_1004",
   "ruamel_yaml 0.15.80 py39hb9d737c_1007",
   "libmambapy 0.24.0 py39hd55135b_1",
   "keyutils 1.6.1 h166bdaf_0",
   "_openmp_mutex 4.5 2_gnu",
   "ruamel.yaml.clib 0.2.6 py39hb9d737c_1",
   "python 3.9.13 h9a8a25e_0_cpython",
   "json5 0.9.5 pyh9f0ad1d_0",
   "colorama 0.4.5 pyhd8ed1ab_0",
   "pysocks 1.7.1 py39hf3d152e_5",
   "yaml 0.2.5 h7f98852_2",
   "rich 12.5.1 pyhd8ed1ab_0",
   "typing_extensions 4.3.0 pyha770c72_0",
   "jsonschema 4.7.2 pyhd8ed1ab_0",
   "openssl 1.1.1q h166bdaf_0",
   "wheel 0.37.1 pyhd8ed1ab_0",
   "pycparser 2.21 pyhd8ed1ab_0",
   "soupsieve 2.3.2.post1 pyhd8ed1ab_0",
   "markupsafe 2.1.1 py39hb9d737c_1",
   "patch 2.7.6 h7f98852_1002",
   "six 1.16.0 pyh6c4a22f_0",
   "yaml-cpp 0.7.0 h27087fc_1",
   "zlib 1.2.12 h166bdaf_2",
   "expat 2.4.8 h27087fc_0",
   "curl 7.83.1 h7bff187_0",
   "tqdm 4.64.0 pyhd8ed1ab_0",
   "joblib 1.1.0 pyhd8ed1ab_0",
   "setuptools 63.2.0 py39hf3d152e_0",
   "git 2.37.1 pl5321h36853c3_0",
   "libstdcxx-ng 12.1.0 ha89aaad_16",
   "perl 5.32.1 2_h7f98852_perl5",
   "urllib3 1.26.10 pyhd8ed1ab_0",
   "sqlite 3.39.2 h4ff8645_0",
   "ruamel.yaml 0.17.21 py39hb9d737c_1",
   "watchgod 0.8.2 pyhd8ed1ab_0",
   "libcurl 7.83.1 h7bff187_0",
   "requests 2.28.1 pyhd8ed1ab_0",
   "toml 0.10.2 pyhd8ed1ab_0",
   "ca-certificates 2022.9.24 ha878542_0",
   "conda-forge-ci-setup 3.21.0 py39h69ce9fc_100",
   "conda-build 3.22.0 py39hf3d152e_2",
   "oniguruma 6.9.8 h166bdaf_0",
   "pip 22.2.2 pyhd8ed1ab_0",
   "click 8.1.3 py39hf3d152e_0",
   "boa 0.11.0 pyha770c72_3",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "jq 1.6 h36c2ea0_1000",
   "conda-env 2.6.0 1",
   "certifi 2022.9.24 pyhd8ed1ab_0"
  ],
  "summary": "HuggingFace/Datasets is an open library of NLP datasets.",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos6",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "docker_image": "quay.io/condaforge/linux-anvil-cos7-x86_64",
  "extend_keys": [
   "pin_run_as_build",
   "ignore_build_only_deps",
   "ignore_version",
   "extend_keys"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.9",
  "r_base": "3.5",
  "target_platform": "linux-64"
 },
 "files": [
  "site-packages/datasets-2.5.1.dist-info/INSTALLER",
  "site-packages/datasets-2.5.1.dist-info/LICENSE",
  "site-packages/datasets-2.5.1.dist-info/METADATA",
  "site-packages/datasets-2.5.1.dist-info/RECORD",
  "site-packages/datasets-2.5.1.dist-info/REQUESTED",
  "site-packages/datasets-2.5.1.dist-info/WHEEL",
  "site-packages/datasets-2.5.1.dist-info/direct_url.json",
  "site-packages/datasets/__init__.py",
  "site-packages/datasets/arrow_dataset.py",
  "site-packages/datasets/arrow_reader.py",
  "site-packages/datasets/arrow_writer.py",
  "site-packages/datasets/builder.py",
  "site-packages/datasets/combine.py",
  "site-packages/datasets/commands/__init__.py",
  "site-packages/datasets/commands/convert.py",
  "site-packages/datasets/commands/datasets_cli.py",
  "site-packages/datasets/commands/dummy_data.py",
  "site-packages/datasets/commands/env.py",
  "site-packages/datasets/commands/run_beam.py",
  "site-packages/datasets/commands/test.py",
  "site-packages/datasets/config.py",
  "site-packages/datasets/data_files.py",
  "site-packages/datasets/dataset_dict.py",
  "site-packages/datasets/download/__init__.py",
  "site-packages/datasets/download/download_config.py",
  "site-packages/datasets/download/download_manager.py",
  "site-packages/datasets/download/mock_download_manager.py",
  "site-packages/datasets/download/streaming_download_manager.py",
  "site-packages/datasets/features/__init__.py",
  "site-packages/datasets/features/audio.py",
  "site-packages/datasets/features/features.py",
  "site-packages/datasets/features/image.py",
  "site-packages/datasets/features/translation.py",
  "site-packages/datasets/filesystems/__init__.py",
  "site-packages/datasets/filesystems/compression.py",
  "site-packages/datasets/filesystems/hffilesystem.py",
  "site-packages/datasets/filesystems/s3filesystem.py",
  "site-packages/datasets/fingerprint.py",
  "site-packages/datasets/formatting/__init__.py",
  "site-packages/datasets/formatting/dataset_wrappers/__init__.py",
  "site-packages/datasets/formatting/dataset_wrappers/torch_iterable_dataset.py",
  "site-packages/datasets/formatting/formatting.py",
  "site-packages/datasets/formatting/jax_formatter.py",
  "site-packages/datasets/formatting/tf_formatter.py",
  "site-packages/datasets/formatting/torch_formatter.py",
  "site-packages/datasets/info.py",
  "site-packages/datasets/inspect.py",
  "site-packages/datasets/io/__init__.py",
  "site-packages/datasets/io/abc.py",
  "site-packages/datasets/io/csv.py",
  "site-packages/datasets/io/generator.py",
  "site-packages/datasets/io/json.py",
  "site-packages/datasets/io/parquet.py",
  "site-packages/datasets/io/text.py",
  "site-packages/datasets/iterable_dataset.py",
  "site-packages/datasets/keyhash.py",
  "site-packages/datasets/load.py",
  "site-packages/datasets/metric.py",
  "site-packages/datasets/naming.py",
  "site-packages/datasets/packaged_modules/__init__.py",
  "site-packages/datasets/packaged_modules/audiofolder/__init__.py",
  "site-packages/datasets/packaged_modules/audiofolder/audiofolder.py",
  "site-packages/datasets/packaged_modules/csv/__init__.py",
  "site-packages/datasets/packaged_modules/csv/csv.py",
  "site-packages/datasets/packaged_modules/folder_based_builder/__init__.py",
  "site-packages/datasets/packaged_modules/folder_based_builder/folder_based_builder.py",
  "site-packages/datasets/packaged_modules/generator/__init__.py",
  "site-packages/datasets/packaged_modules/generator/generator.py",
  "site-packages/datasets/packaged_modules/imagefolder/__init__.py",
  "site-packages/datasets/packaged_modules/imagefolder/imagefolder.py",
  "site-packages/datasets/packaged_modules/json/__init__.py",
  "site-packages/datasets/packaged_modules/json/json.py",
  "site-packages/datasets/packaged_modules/pandas/__init__.py",
  "site-packages/datasets/packaged_modules/pandas/pandas.py",
  "site-packages/datasets/packaged_modules/parquet/__init__.py",
  "site-packages/datasets/packaged_modules/parquet/parquet.py",
  "site-packages/datasets/packaged_modules/text/__init__.py",
  "site-packages/datasets/packaged_modules/text/text.py",
  "site-packages/datasets/py.typed",
  "site-packages/datasets/search.py",
  "site-packages/datasets/splits.py",
  "site-packages/datasets/streaming.py",
  "site-packages/datasets/table.py",
  "site-packages/datasets/tasks/__init__.py",
  "site-packages/datasets/tasks/automatic_speech_recognition.py",
  "site-packages/datasets/tasks/base.py",
  "site-packages/datasets/tasks/image_classification.py",
  "site-packages/datasets/tasks/language_modeling.py",
  "site-packages/datasets/tasks/question_answering.py",
  "site-packages/datasets/tasks/summarization.py",
  "site-packages/datasets/tasks/text_classification.py",
  "site-packages/datasets/utils/__init__.py",
  "site-packages/datasets/utils/_hf_hub_fixes.py",
  "site-packages/datasets/utils/beam_utils.py",
  "site-packages/datasets/utils/deprecation_utils.py",
  "site-packages/datasets/utils/doc_utils.py",
  "site-packages/datasets/utils/download_manager.py",
  "site-packages/datasets/utils/extract.py",
  "site-packages/datasets/utils/file_utils.py",
  "site-packages/datasets/utils/filelock.py",
  "site-packages/datasets/utils/info_utils.py",
  "site-packages/datasets/utils/logging.py",
  "site-packages/datasets/utils/metadata.py",
  "site-packages/datasets/utils/patching.py",
  "site-packages/datasets/utils/py_utils.py",
  "site-packages/datasets/utils/readme.py",
  "site-packages/datasets/utils/resources/__init__.py",
  "site-packages/datasets/utils/resources/creators.json",
  "site-packages/datasets/utils/resources/languages.json",
  "site-packages/datasets/utils/resources/multilingualities.json",
  "site-packages/datasets/utils/resources/readme_structure.yaml",
  "site-packages/datasets/utils/resources/size_categories.json",
  "site-packages/datasets/utils/resources/standard_licenses.tsv",
  "site-packages/datasets/utils/resources/tasks.json",
  "site-packages/datasets/utils/stratify.py",
  "site-packages/datasets/utils/tf_utils.py",
  "site-packages/datasets/utils/typing.py",
  "site-packages/datasets/utils/version.py"
 ],
 "index": {
  "arch": null,
  "build": "pyhd8ed1ab_0",
  "build_number": 0,
  "depends": [
   "aiohttp",
   "dataclasses",
   "dill <0.3.6",
   "fsspec >=2021.05.0",
   "huggingface_hub >=0.1.0,<1.0.0",
   "importlib-metadata",
   "multiprocess",
   "numpy >=1.17",
   "packaging",
   "pandas",
   "pyarrow >=6.0.0",
   "python >=3.6",
   "python-xxhash",
   "requests >=2.19.0",
   "responses <0.19",
   "tqdm >=4.62.1"
  ],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "name": "datasets",
  "noarch": "python",
  "platform": null,
  "subdir": "noarch",
  "timestamp": 1664420145732,
  "version": "2.5.1"
 },
 "metadata_version": 1,
 "name": "datasets",
 "raw_recipe": "{% set name = \"datasets\" %}\n{% set version = \"2.5.1\" %}\n\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 6211cf87eff086ec34f4ec4ab49ff9d1cab0df5b53e96ac641dc3071b61cf328\n\nbuild:\n  noarch: python\n  number: 0\n  entry_points:\n    - datasets-cli=datasets.commands.datasets_cli:main\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.6\n  run:\n    - aiohttp\n    - dataclasses\n    - dill <0.3.6\n    - fsspec >=2021.05.0\n    - huggingface_hub >=0.1.0,<1.0.0\n    - importlib-metadata\n    - multiprocess\n    - numpy >=1.17\n    - packaging\n    - pandas\n    - pyarrow >=6.0.0\n    - python >=3.6\n    - python-xxhash\n    - requests >=2.19.0\n    - responses <0.19\n    - tqdm >=4.62.1\n\ntest:\n  imports:\n    - datasets\n    - datasets.commands\n    - datasets.features\n    - datasets.filesystems\n    - datasets.formatting\n    - datasets.io\n    - datasets.packaged_modules\n    - datasets.packaged_modules.csv\n    - datasets.packaged_modules.json\n    - datasets.packaged_modules.pandas\n    - datasets.packaged_modules.parquet\n    - datasets.packaged_modules.text\n    - datasets.tasks\n    - datasets.utils\n    - datasets.utils.resources\n  commands:\n    - pip check\n    - datasets-cli --help\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/huggingface/datasets\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n  summary: HuggingFace/Datasets is an open library of NLP datasets.\n  description: |\n    Datasets is a lightweight library providing one-line dataloaders for many\n    public datasets and one liners to download and pre-process any of the number\n    of datasets major public datasets provided on the HuggingFace Datasets Hub.\n    Datasets are ready to use in a dataloader for training/evaluating a ML model\n    (Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\n    simple, fast, and reproducible data pre-processing for the above public\n    datasets as well as your own local datasets in CSV/JSON/text.\n  doc_url: https://huggingface.co/docs/datasets/\n  dev_url: https://github.com/huggingface/datasets\n\nextra:\n  recipe-maintainers:\n    - oblute\n    - Tata17\n    - thewchan\n    - mxr-conda\n",
 "rendered_recipe": {
  "about": {
   "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.\n",
   "dev_url": "https://github.com/huggingface/datasets",
   "doc_url": "https://huggingface.co/docs/datasets/",
   "home": "https://github.com/huggingface/datasets",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "LICENSE",
   "summary": "HuggingFace/Datasets is an open library of NLP datasets."
  },
  "build": {
   "entry_points": [
    "datasets-cli=datasets.commands.datasets_cli:main"
   ],
   "noarch": "python",
   "number": "0",
   "script": "/home/conda/feedstock_root/build_artifacts/datasets_1664420006576/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/bin/python -m pip install . -vv",
   "string": "pyhd8ed1ab_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "Tata17",
    "mxr-conda",
    "oblute",
    "thewchan"
   ]
  },
  "package": {
   "name": "datasets",
   "version": "2.5.1"
  },
  "requirements": {
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 2_gnu",
    "bzip2 1.0.8 h7f98852_4",
    "ca-certificates 2022.9.24 ha878542_0",
    "ld_impl_linux-64 2.36.1 hea4e1c9_2",
    "libffi 3.4.2 h7f98852_5",
    "libgcc-ng 12.1.0 h8d9b700_16",
    "libgomp 12.1.0 h8d9b700_16",
    "libnsl 2.0.0 h7f98852_0",
    "libsqlite 3.39.3 h753d276_0",
    "libuuid 2.32.1 h7f98852_1000",
    "libzlib 1.2.12 h166bdaf_3",
    "ncurses 6.3 h27087fc_1",
    "openssl 3.0.5 h166bdaf_2",
    "pip 22.2.2 pyhd8ed1ab_0",
    "python 3.10.6 ha86cf86_0_cpython",
    "readline 8.1.2 h0f457ee_0",
    "setuptools 65.4.0 pyhd8ed1ab_0",
    "tk 8.6.12 h27826a3_0",
    "tzdata 2022d h191b570_0",
    "wheel 0.37.1 pyhd8ed1ab_0",
    "xz 5.2.6 h166bdaf_0"
   ],
   "run": [
    "aiohttp",
    "dataclasses",
    "dill <0.3.6",
    "fsspec >=2021.05.0",
    "huggingface_hub >=0.1.0,<1.0.0",
    "importlib-metadata",
    "multiprocess",
    "numpy >=1.17",
    "packaging",
    "pandas",
    "pyarrow >=6.0.0",
    "python >=3.6",
    "python-xxhash",
    "requests >=2.19.0",
    "responses <0.19",
    "tqdm >=4.62.1"
   ]
  },
  "source": {
   "sha256": "6211cf87eff086ec34f4ec4ab49ff9d1cab0df5b53e96ac641dc3071b61cf328",
   "url": "https://pypi.io/packages/source/d/datasets/datasets-2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "datasets-cli --help"
   ],
   "imports": [
    "datasets",
    "datasets.commands",
    "datasets.features",
    "datasets.filesystems",
    "datasets.formatting",
    "datasets.io",
    "datasets.packaged_modules",
    "datasets.packaged_modules.csv",
    "datasets.packaged_modules.json",
    "datasets.packaged_modules.pandas",
    "datasets.packaged_modules.parquet",
    "datasets.packaged_modules.text",
    "datasets.tasks",
    "datasets.utils",
    "datasets.utils.resources"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "version": "2.5.1"
}