{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.23.3",
  "conda_version": "22.11.1",
  "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
  "dev_url": "https://github.com/apache/airflow",
  "doc_url": "http://pythonhosted.org/airflow/profiling.html",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "parent_recipe": {
    "name": "airflow-split",
    "path": "/Users/runner/work/1/s/recipe",
    "version": "2.5.2"
   },
   "recipe-maintainers": [
    "sodre",
    "halldc",
    "xylar"
   ]
  },
  "home": "http://airflow.apache.org",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_file": [
   "LICENSE",
   "NOTICE",
   "licenses/LICENSE-d3js.txt",
   "licenses/LICENSE-d3-tip.txt",
   "licenses/LICENSE-moment-strftime.txt",
   "licenses/LICENSE-elasticmock.txt",
   "licenses/LICENSE-eonasdan-bootstrap-datetimepicker.txt",
   "licenses/LICENSE-moment.txt",
   "licenses/LICENSE-bootstrap3-typeahead.txt",
   "licenses/LICENSE-jqclock.txt",
   "licenses/LICENSE-dagre-d3.txt",
   "licenses/LICENSE-datatables.txt",
   "licenses/LICENSE-flask-kerberos.txt",
   "licenses/LICENSE-hue.txt",
   "licenses/LICENSE-jquery.txt",
   "licenses/LICENSE-bootstrap.txt",
   "licenses/LICENSE-d3-shape.txt",
   "licenses/LICENSE-normalize.txt"
  ],
  "root_pkgs": [
   "mamba 1.1.0 py310h6bde348_2",
   "gettext 0.21.1 h8a4c099_0",
   "pthread-stubs 0.4 hc929b4f_1001",
   "markupsafe 2.1.2 py310h90acd4f_0",
   "requests 2.28.2 pyhd8ed1ab_0",
   "conda-env 2.6.0 1",
   "six 1.16.0 pyh6c4a22f_0",
   "psutil 5.9.4 py310h90acd4f_0",
   "attrs 22.2.0 pyh71513ae_0",
   "anyio 3.6.2 pyhd8ed1ab_0",
   "importlib-metadata 6.0.0 pyha770c72_0",
   "libcxx 14.0.6 hccf4f1f_0",
   "tornado 6.2 py310h90acd4f_1",
   "colorama 0.4.6 pyhd8ed1ab_0",
   "toml 0.10.2 pyhd8ed1ab_0",
   "jq 1.6 hc929b4f_1000",
   "yaml 0.2.5 h0d85af4_2",
   "xorg-libxau 1.0.9 h35c211d_0",
   "typing_extensions 4.5.0 pyha770c72_0",
   "watchgod 0.8.2 pyhd8ed1ab_0",
   "anaconda-client 1.11.1 pyhd8ed1ab_0",
   "tzdata 2022g h191b570_0",
   "ld64 609 hc6ad406_11",
   "ruamel.yaml 0.17.21 py310h90acd4f_2",
   "pyopenssl 23.0.0 pyhd8ed1ab_0",
   "typing-extensions 4.5.0 hd8ed1ab_0",
   "prompt-toolkit 3.0.38 pyha770c72_0",
   "pyyaml 6.0 py310h90acd4f_5",
   "openjpeg 2.5.0 h13ac156_2",
   "libzlib 1.2.13 hfd90126_4",
   "urllib3 1.26.14 pyhd8ed1ab_0",
   "cffi 1.15.1 py310ha78151a_3",
   "pygments 2.14.0 pyhd8ed1ab_0",
   "chardet 5.1.0 py310h2ec42d9_0",
   "conda-package-handling 2.0.2 pyh38be061_0",
   "reproc 14.2.4 hb7f2c08_0",
   "rich 13.3.2 pyhd8ed1ab_0",
   "mdurl 0.1.0 pyhd8ed1ab_0",
   "freetype 2.12.1 h3f81eb7_1",
   "pcre2 10.40 h1c4e4bc_0",
   "libsolv 0.7.22 hd9580d2_0",
   "glob2 0.7 py_0",
   "nbformat 5.7.3 pyhd8ed1ab_0",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "wheel 0.38.4 pyhd8ed1ab_0",
   "libjpeg-turbo 2.1.5.1 hb7f2c08_0",
   "lcms2 2.15 h2dcdeff_1",
   "xorg-libxdmcp 1.1.3 h35c211d_0",
   "toolz 0.12.0 pyhd8ed1ab_0",
   "ncurses 6.3 h96cf925_1",
   "expat 2.5.0 hf0c8a7f_0",
   "cctools 973.0.1 h76f1dac_11",
   "libnghttp2 1.51.0 he2ab024_0",
   "libedit 3.1.20191231 h0678c8f_2",
   "markdown-it-py 2.2.0 pyhd8ed1ab_0",
   "perl 5.32.1 2_h0d85af4_perl5",
   "sigtool 0.1.3 h88f4db0_0",
   "libwebp-base 1.3.0 hb7f2c08_0",
   "joblib 1.2.0 pyhd8ed1ab_0",
   "libdeflate 1.17 hac1461d_0",
   "conda 22.11.1 py310h2ec42d9_1",
   "pysocks 1.7.1 pyha2e5f31_6",
   "soupsieve 2.3.2.post1 pyhd8ed1ab_0",
   "jinja2 3.1.2 pyhd8ed1ab_1",
   "lz4-c 1.9.4 hf0c8a7f_0",
   "anaconda-project 0.11.1 pyhd8ed1ab_0",
   "git 2.40.0 pl5321h0195497_0",
   "prompt_toolkit 3.0.38 hd8ed1ab_0",
   "ld64_osx-64 609 hfd63004_11",
   "wcwidth 0.2.6 pyhd8ed1ab_0",
   "sniffio 1.3.0 pyhd8ed1ab_0",
   "libllvm14 14.0.6 h5b596cc_1",
   "pip 23.0.1 pyhd8ed1ab_0",
   "conda-pack 0.7.0 pyh6c4a22f_0",
   "ca-certificates 2022.12.7 h033912b_0",
   "ripgrep 13.0.0 hbbacdb1_2",
   "conda-forge-ci-setup 3.29.1 py310h22f808f_100",
   "fmt 9.1.0 hb8565cd_0",
   "zstandard 0.19.0 py310h3cf44b0_1",
   "filelock 3.9.1 pyhd8ed1ab_0",
   "patch 2.7.6 hbcf498f_1002",
   "pkginfo 1.9.6 pyhd8ed1ab_0",
   "libffi 3.4.2 h0d85af4_5",
   "python_abi 3.10 3_cp310",
   "traitlets 5.9.0 pyhd8ed1ab_0",
   "readline 8.1.2 h3899abd_0",
   "pluggy 1.0.0 pyhd8ed1ab_5",
   "charset-normalizer 2.1.1 pyhd8ed1ab_0",
   "defusedxml 0.7.1 pyhd8ed1ab_0",
   "libcurl 7.87.0 h6df9250_0",
   "libxcb 1.13 h0d85af4_1004",
   "libtiff 4.5.0 hd920806_5",
   "reproc-cpp 14.2.4 hf0c8a7f_0",
   "liblief 0.12.3 hf0c8a7f_0",
   "tapi 1100.0.11 h9ce4665_0",
   "zipp 3.15.0 pyhd8ed1ab_0",
   "setuptools 65.6.3 pyhd8ed1ab_0",
   "conda-build 3.23.3 py310h2ec42d9_1",
   "jupyter_core 5.2.0 py310h2ec42d9_0",
   "cryptography 39.0.1 py310hdd0c95c_0",
   "importlib_resources 5.12.0 pyhd8ed1ab_0",
   "libssh2 1.10.0 h47af595_3",
   "boa 0.14.0 pyhd8ed1ab_2",
   "libpng 1.6.39 ha978bb4_0",
   "python-libarchive-c 4.0 py310h2ec42d9_2",
   "xz 5.2.6 h775f41a_0",
   "python 3.10.9 he7542f4_0_cpython",
   "python-fastjsonschema 2.16.3 pyhd8ed1ab_0",
   "yaml-cpp 0.7.0 hf0c8a7f_2",
   "tqdm 4.64.1 pyhd8ed1ab_0",
   "backports 1.0 pyhd8ed1ab_3",
   "zstd 1.5.2 hbc0c0cd_6",
   "bzip2 1.0.8 h0d85af4_4",
   "pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0",
   "c-ares 1.18.1 h0d85af4_0",
   "json5 0.9.5 pyh9f0ad1d_0",
   "py-lief 0.12.3 py310h7a76584_0",
   "libsqlite 3.40.0 ha978bb4_0",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "icu 70.1 h96cf925_0",
   "pycosat 0.6.4 py310h90acd4f_1",
   "clyent 1.2.2 py_1",
   "brotlipy 0.7.0 py310h90acd4f_1005",
   "click 8.1.3 unix_pyhd8ed1ab_2",
   "curl 7.87.0 h6df9250_0",
   "lerc 4.0.0 hb486fe8_0",
   "conda-package-streaming 0.7.0 pyhd8ed1ab_1",
   "pillow 9.4.0 py310h6b2f720_2",
   "jsonschema 4.17.3 pyhd8ed1ab_0",
   "libmamba 1.1.0 h8b63968_2",
   "openssl 3.1.0 hfd90126_0",
   "ruamel_yaml 0.15.80 py310h90acd4f_1008",
   "oniguruma 6.9.8 hac89ed1_0",
   "libxml2 2.10.3 hb9e07b5_0",
   "libmambapy 1.1.0 py310hb15139c_2",
   "cctools_osx-64 973.0.1 hcc6d90d_11",
   "libiconv 1.17 hac89ed1_0",
   "dataclasses 0.8 pyhc8e2a94_3",
   "lzo 2.10 haf1e3a3_1000",
   "krb5 1.20.1 h049b76e_0",
   "pybind11-abi 4 hd8ed1ab_3",
   "ruamel.yaml.clib 0.2.7 py310h90acd4f_1",
   "pytz 2022.7.1 pyhd8ed1ab_0",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "libarchive 3.5.2 hbf7dfe4_3",
   "certifi 2022.12.7 pyhd8ed1ab_0",
   "platformdirs 3.1.1 pyhd8ed1ab_0",
   "pyrsistent 0.19.3 py310h90acd4f_0",
   "pycparser 2.21 pyhd8ed1ab_0",
   "tk 8.6.12 h5dbffcc_0",
   "libev 4.33 haf1e3a3_1",
   "idna 3.4 pyhd8ed1ab_0",
   "beautifulsoup4 4.11.2 pyha770c72_0"
  ],
  "summary": "Airflow is a platform to programmatically author, schedule and monitor\nworkflows\n",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "CONDA_BUILD_SYSROOT": "/Applications/Xcode_13.2.1.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk",
  "MACOSX_DEPLOYMENT_TARGET": "10.9",
  "c_compiler": "clang",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "clangxx",
  "extend_keys": [
   "ignore_build_only_deps",
   "pin_run_as_build",
   "extend_keys",
   "ignore_version"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "macos_machine": "x86_64-apple-darwin13.4.0",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.9.* *_cpython",
  "r_base": "3.5",
  "target_platform": "osx-64"
 },
 "conda_pkg_format": "2",
 "files": [],
 "index": {
  "arch": "x86_64",
  "build": "py39h6e9494a_0",
  "build_number": 0,
  "depends": [
   "airflow >=2.5.2,<2.5.3.0a0",
   "fastavro >=0.21.19",
   "pandas >=0.14.1",
   "python >=3.9,<3.10.0a0",
   "python-hdfs >=2.0.4",
   "python_abi 3.9.* *_cp39",
   "requests-kerberos >=0.7.0"
  ],
  "license": "Apache-2.0",
  "name": "airflow-with-apache-webhdfs",
  "platform": "osx",
  "subdir": "osx-64",
  "timestamp": 1678911243365,
  "version": "2.5.2"
 },
 "metadata_version": 1,
 "name": "airflow-with-apache-webhdfs",
 "raw_recipe": "# This file created by conda-build 3.23.3\n# ------------------------------------------------\n\npackage:\n  name: airflow-with-apache-webhdfs\n  version: 2.5.2\nsource:\n  fn: airflow-2.5.2.tar.gz\n  sha256: 7ed17a4107c0f80904615d1043eb6ece8f58ac7a5390499208bade7a4010fda6\n  url: https://github.com/apache/airflow/archive/2.5.2.tar.gz\nbuild:\n  noarch: false\n  noarch_python: false\n  number: '0'\n  string: py39h6e9494a_0\nrequirements:\n  host:\n    - bzip2 1.0.8 h0d85af4_4\n    - ca-certificates 2022.12.7 h033912b_0\n    - libffi 3.4.2 h0d85af4_5\n    - libsqlite 3.40.0 ha978bb4_0\n    - libzlib 1.2.13 hfd90126_4\n    - ncurses 6.3 h96cf925_1\n    - openssl 3.1.0 hfd90126_0\n    - python 3.9.16 h709bd14_0_cpython\n    - readline 8.1.2 h3899abd_0\n    - tk 8.6.12 h5dbffcc_0\n    - tzdata 2022g h191b570_0\n    - xz 5.2.6 h775f41a_0\n  run:\n    - airflow >=2.5.2,<2.5.3.0a0\n    - fastavro >=0.21.19\n    - pandas>=0.14.1\n    - python >=3.9,<3.10.0a0\n    - python-hdfs >=2.0.4\n    - python_abi 3.9.* *_cp39\n    - requests-kerberos >=0.7.0\ntest:\n  commands:\n    - pip check\n  imports:\n    - airflow\n    - airflow.hooks.webhdfs_hook\n    - hdfs\n  requires:\n    - pip\nabout:\n  description: 'Use airflow to author workflows as directed acyclic graphs (DAGs)\n\n    of tasks. The airflow scheduler executes your tasks on an array of\n\n    workers while following the specified dependencies. Rich command\n\n    line utilities make performing complex surgeries on DAGs a snap.\n\n    The rich user interface makes it easy to visualize pipelines\n\n    running in production, monitor progress, and troubleshoot issues\n\n    when needed.\n\n\n    When workflows are defined as code, they become more maintainable,\n\n    versionable, testable, and collaborative.\n\n    '\n  dev_url: https://github.com/apache/airflow\n  doc_url: http://pythonhosted.org/airflow/profiling.html\n  home: http://airflow.apache.org\n  license: Apache-2.0\n  license_file:\n    - LICENSE\n    - NOTICE\n    - licenses/LICENSE-bootstrap.txt\n    - licenses/LICENSE-bootstrap3-typeahead.txt\n    - licenses/LICENSE-d3-shape.txt\n    - licenses/LICENSE-d3-tip.txt\n    - licenses/LICENSE-d3js.txt\n    - licenses/LICENSE-dagre-d3.txt\n    - licenses/LICENSE-datatables.txt\n    - licenses/LICENSE-elasticmock.txt\n    - licenses/LICENSE-eonasdan-bootstrap-datetimepicker.txt\n    - licenses/LICENSE-flask-kerberos.txt\n    - licenses/LICENSE-hue.txt\n    - licenses/LICENSE-jqclock.txt\n    - licenses/LICENSE-jquery.txt\n    - licenses/LICENSE-moment-strftime.txt\n    - licenses/LICENSE-moment.txt\n    - licenses/LICENSE-normalize.txt\n  summary: 'Airflow is a platform to programmatically author, schedule and monitor\n\n    workflows\n\n    '\nextra:\n  copy_test_source_files: true\n  final: true\n  recipe-maintainers:\n    - halldc\n    - sodre\n    - xylar\n",
 "rendered_recipe": {
  "about": {
   "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
   "dev_url": "https://github.com/apache/airflow",
   "doc_url": "http://pythonhosted.org/airflow/profiling.html",
   "home": "http://airflow.apache.org",
   "license": "Apache-2.0",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "licenses/LICENSE-bootstrap.txt",
    "licenses/LICENSE-bootstrap3-typeahead.txt",
    "licenses/LICENSE-d3-shape.txt",
    "licenses/LICENSE-d3-tip.txt",
    "licenses/LICENSE-d3js.txt",
    "licenses/LICENSE-dagre-d3.txt",
    "licenses/LICENSE-datatables.txt",
    "licenses/LICENSE-elasticmock.txt",
    "licenses/LICENSE-eonasdan-bootstrap-datetimepicker.txt",
    "licenses/LICENSE-flask-kerberos.txt",
    "licenses/LICENSE-hue.txt",
    "licenses/LICENSE-jqclock.txt",
    "licenses/LICENSE-jquery.txt",
    "licenses/LICENSE-moment-strftime.txt",
    "licenses/LICENSE-moment.txt",
    "licenses/LICENSE-normalize.txt"
   ],
   "summary": "Airflow is a platform to programmatically author, schedule and monitor\nworkflows\n"
  },
  "build": {
   "noarch": false,
   "noarch_python": false,
   "number": "0",
   "string": "py39h6e9494a_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "halldc",
    "sodre",
    "xylar"
   ]
  },
  "package": {
   "name": "airflow-with-apache-webhdfs",
   "version": "2.5.2"
  },
  "requirements": {
   "host": [
    "bzip2 1.0.8 h0d85af4_4",
    "ca-certificates 2022.12.7 h033912b_0",
    "libffi 3.4.2 h0d85af4_5",
    "libsqlite 3.40.0 ha978bb4_0",
    "libzlib 1.2.13 hfd90126_4",
    "ncurses 6.3 h96cf925_1",
    "openssl 3.1.0 hfd90126_0",
    "python 3.9.16 h709bd14_0_cpython",
    "readline 8.1.2 h3899abd_0",
    "tk 8.6.12 h5dbffcc_0",
    "tzdata 2022g h191b570_0",
    "xz 5.2.6 h775f41a_0"
   ],
   "run": [
    "airflow >=2.5.2,<2.5.3.0a0",
    "fastavro >=0.21.19",
    "pandas>=0.14.1",
    "python >=3.9,<3.10.0a0",
    "python-hdfs >=2.0.4",
    "python_abi 3.9.* *_cp39",
    "requests-kerberos >=0.7.0"
   ]
  },
  "source": {
   "fn": "airflow-2.5.2.tar.gz",
   "sha256": "7ed17a4107c0f80904615d1043eb6ece8f58ac7a5390499208bade7a4010fda6",
   "url": "https://github.com/apache/airflow/archive/2.5.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "airflow",
    "airflow.hooks.webhdfs_hook",
    "hdfs"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "version": "2.5.2"
}