{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.23.3",
  "conda_version": "23.1.0",
  "description": "The Adaptive scheduler solves the following problem, you need to run a few 100\nlearners and can use >1k cores. `ipyparallel` and `dask.distributed` provide\nvery powerful engines for interactive sessions. However, when you want to\nconnect to >1k cores it starts to struggle. Besides that, on a shared cluster\nthere is often the problem of starting an interactive session with ample space\navailable. Our approach is to schedule a different job for each `\nadaptive.Learner`. The creation and running of these jobs are managed by `\nadaptive-scheduler`. This means that your calculation will definitely run, even\nthough the cluster might be fully occupied at the moment. Because of this\napproach, there is almost no limit to how many cores you want to use. You can\neither use 10 nodes for 1 job (`learner`) or 1 core for 1 job (`learner`) while\nscheduling hundreds of jobs. Everything is written such that the computation is\nmaximally local. This means that is one of the jobs crashes, there is no\nproblem and it will automatically schedule a new one and continue the\ncalculation where it left off (because of Adaptive's periodic saving\nfunctionality). Even if the central \"job manager\" dies, the jobs will continue\nto run (although no new jobs will be scheduled.)\n",
  "dev_url": "https://github.com/basnijholt/adaptive-scheduler",
  "doc_url": "http://adaptive-scheduler.readthedocs.io",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "basnijholt"
   ]
  },
  "home": "http://github.com/basnijholt/adaptive-scheduler",
  "identifiers": [],
  "keywords": [],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "license_file": "LICENSE",
  "root_pkgs": [
   "jinja2 3.1.2 pyhd8ed1ab_1",
   "watchgod 0.8.2 pyhd8ed1ab_0",
   "pcre2 10.40 hc3806b6_0",
   "attrs 22.2.0 pyh71513ae_0",
   "ncurses 6.3 h27087fc_1",
   "_openmp_mutex 4.5 2_gnu",
   "freetype 2.12.1 hca18f0e_1",
   "git 2.39.2 pl5321h693f4a3_0",
   "jsonschema 4.17.3 pyhd8ed1ab_0",
   "wheel 0.38.4 pyhd8ed1ab_0",
   "icu 70.1 h27087fc_0",
   "conda-package-streaming 0.7.0 pyhd8ed1ab_1",
   "zstd 1.5.2 h3eb15da_6",
   "ca-certificates 2022.12.7 ha878542_0",
   "python-libarchive-c 4.0 py310hff52083_2",
   "ruamel.yaml 0.17.21 py310h1fa729e_3",
   "tqdm 4.65.0 pyhd8ed1ab_1",
   "conda-pack 0.7.0 pyh6c4a22f_0",
   "clyent 1.2.2 py_1",
   "_libgcc_mutex 0.1 conda_forge",
   "pycparser 2.21 pyhd8ed1ab_0",
   "pygments 2.14.0 pyhd8ed1ab_0",
   "pillow 9.4.0 py310h065c6d2_2",
   "pybind11-abi 4 hd8ed1ab_3",
   "typing_extensions 4.5.0 pyha770c72_0",
   "glob2 0.7 py_0",
   "anyio 3.6.2 pyhd8ed1ab_0",
   "libmamba 1.1.0 h70b1f8a_2",
   "lz4-c 1.9.4 hcb278e6_0",
   "typing-extensions 4.5.0 hd8ed1ab_0",
   "nbformat 5.7.3 pyhd8ed1ab_0",
   "readline 8.1.2 h0f457ee_0",
   "urllib3 1.26.14 pyhd8ed1ab_0",
   "pycosat 0.6.4 py310h5764c6d_1",
   "json5 0.9.5 pyh9f0ad1d_0",
   "libnghttp2 1.52.0 h61bc06f_0",
   "lzo 2.10 h516909a_1000",
   "reproc 14.2.4 h0b41bf4_0",
   "libstdcxx-ng 12.2.0 h46fd767_19",
   "xz 5.2.6 h166bdaf_0",
   "platformdirs 3.1.0 pyhd8ed1ab_0",
   "ruamel.yaml.clib 0.2.7 py310h1fa729e_1",
   "dataclasses 0.8 pyhc8e2a94_3",
   "tk 8.6.12 h27826a3_0",
   "pytz 2022.7.1 pyhd8ed1ab_0",
   "boa 0.14.0 pyhd8ed1ab_2",
   "libiconv 1.17 h166bdaf_0",
   "idna 3.4 pyhd8ed1ab_0",
   "anaconda-client 1.11.1 pyhd8ed1ab_0",
   "keyutils 1.6.1 h166bdaf_0",
   "six 1.16.0 pyh6c4a22f_0",
   "chardet 5.1.0 py310hff52083_0",
   "libjpeg-turbo 2.1.5.1 h0b41bf4_0",
   "mamba 1.1.0 py310h51d5547_2",
   "ruamel_yaml 0.15.80 py310h5764c6d_1008",
   "libtiff 4.5.0 hddfeb54_5",
   "charset-normalizer 2.1.1 pyhd8ed1ab_0",
   "python 3.10.9 he550d4f_0_cpython",
   "tzdata 2022g h191b570_0",
   "certifi 2022.12.7 pyhd8ed1ab_0",
   "py-lief 0.12.3 py310hd8f1fbe_0",
   "requests 2.28.2 pyhd8ed1ab_0",
   "openjpeg 2.5.0 hfec8fc6_2",
   "prompt_toolkit 3.0.38 hd8ed1ab_0",
   "libcurl 7.88.1 hdc1c0ab_0",
   "libev 4.33 h516909a_1",
   "libgcc-ng 12.2.0 h65d4601_19",
   "jupyter_core 5.2.0 py310hff52083_0",
   "lerc 4.0.0 h27087fc_0",
   "libffi 3.4.2 h7f98852_5",
   "expat 2.5.0 h27087fc_0",
   "wcwidth 0.2.6 pyhd8ed1ab_0",
   "ripgrep 13.0.0 h2f28480_2",
   "pyrsistent 0.19.3 py310h1fa729e_0",
   "python_abi 3.10 3_cp310",
   "zstandard 0.19.0 py310hdeb6495_1",
   "fmt 9.1.0 h924138e_0",
   "libdeflate 1.17 h0b41bf4_0",
   "libsolv 0.7.22 h6239696_0",
   "joblib 1.2.0 pyhd8ed1ab_0",
   "libgomp 12.2.0 h65d4601_19",
   "importlib-metadata 6.0.0 pyha770c72_0",
   "setuptools 65.6.3 pyhd8ed1ab_0",
   "xorg-libxdmcp 1.1.3 h7f98852_0",
   "conda-package-handling 2.0.2 pyh38be061_0",
   "tini 0.19.0 h166bdaf_1",
   "xorg-libxau 1.0.9 h7f98852_0",
   "curl 7.88.1 hdc1c0ab_0",
   "patchelf 0.17.2 h58526e2_0",
   "python-fastjsonschema 2.16.3 pyhd8ed1ab_0",
   "mdurl 0.1.0 pyhd8ed1ab_0",
   "sniffio 1.3.0 pyhd8ed1ab_0",
   "traitlets 5.9.0 pyhd8ed1ab_0",
   "pluggy 1.0.0 pyhd8ed1ab_5",
   "yaml-cpp 0.7.0 h27087fc_2",
   "krb5 1.20.1 h81ceb04_0",
   "psutil 5.9.4 py310h5764c6d_0",
   "liblief 0.12.3 h27087fc_0",
   "soupsieve 2.3.2.post1 pyhd8ed1ab_0",
   "zipp 3.15.0 pyhd8ed1ab_0",
   "rich 13.3.2 pyhd8ed1ab_0",
   "tornado 6.2 py310h5764c6d_1",
   "importlib_resources 5.12.0 pyhd8ed1ab_0",
   "pysocks 1.7.1 pyha2e5f31_6",
   "patch 2.7.6 h7f98852_1002",
   "libuuid 2.32.1 h7f98852_1000",
   "cffi 1.15.1 py310h255011f_3",
   "pthread-stubs 0.4 h36c2ea0_1001",
   "markdown-it-py 2.2.0 pyhd8ed1ab_0",
   "yaml 0.2.5 h7f98852_2",
   "toml 0.10.2 pyhd8ed1ab_0",
   "lcms2 2.15 haa2dc70_1",
   "libedit 3.1.20191231 he28a2e2_2",
   "libxcb 1.13 h7f98852_1004",
   "pkginfo 1.9.6 pyhd8ed1ab_0",
   "filelock 3.9.0 pyhd8ed1ab_0",
   "defusedxml 0.7.1 pyhd8ed1ab_0",
   "conda 23.1.0 py310hff52083_0",
   "c-ares 1.18.1 h7f98852_0",
   "perl 5.32.1 2_h7f98852_perl5",
   "libpng 1.6.39 h753d276_0",
   "su-exec 0.2 h166bdaf_1003",
   "libzlib 1.2.13 h166bdaf_4",
   "gettext 0.21.1 h27087fc_0",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "beautifulsoup4 4.11.2 pyha770c72_0",
   "conda-build 3.23.3 py310hff52083_1",
   "ld_impl_linux-64 2.40 h41732ed_0",
   "pip 23.0.1 pyhd8ed1ab_0",
   "toolz 0.12.0 pyhd8ed1ab_0",
   "backports 1.0 pyhd8ed1ab_3",
   "cryptography 39.0.2 py310h34c0648_0",
   "pyyaml 6.0 py310h5764c6d_5",
   "colorama 0.4.6 pyhd8ed1ab_0",
   "anaconda-project 0.11.1 pyhd8ed1ab_0",
   "libarchive 3.5.2 hada088e_3",
   "markupsafe 2.1.2 py310h1fa729e_0",
   "libssh2 1.10.0 hf14f497_3",
   "brotlipy 0.7.0 py310h5764c6d_1005",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "libxml2 2.10.3 h7463322_0",
   "pyopenssl 23.0.0 pyhd8ed1ab_0",
   "libnsl 2.0.0 h7f98852_0",
   "pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0",
   "prompt-toolkit 3.0.38 pyha770c72_0",
   "libwebp-base 1.2.4 h166bdaf_0",
   "libsqlite 3.40.0 h753d276_0",
   "reproc-cpp 14.2.4 hcb278e6_0",
   "bzip2 1.0.8 h7f98852_4",
   "libmambapy 1.1.0 py310h69aa5bf_2",
   "conda-env 2.6.0 1",
   "oniguruma 6.9.8 h166bdaf_0",
   "jq 1.6 h36c2ea0_1000",
   "conda-forge-ci-setup 3.29.1 py310hce54274_100",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "click 8.1.3 unix_pyhd8ed1ab_2",
   "openssl 3.1.0 h0b41bf4_0"
  ],
  "summary": "An asynchronous scheduler for Adaptive",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos6",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "docker_image": "quay.io/condaforge/linux-anvil-cos7-x86_64",
  "extend_keys": [
   "ignore_version",
   "extend_keys",
   "pin_run_as_build",
   "ignore_build_only_deps"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "python",
   "numpy"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.8.* *_cpython",
  "r_base": "3.5",
  "target_platform": "linux-64"
 },
 "conda_pkg_format": "2",
 "files": [
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/AUTHORS.md",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/INSTALLER",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/LICENSE",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/METADATA",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/RECORD",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/REQUESTED",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/WHEEL",
  "lib/python3.8/site-packages/adaptive_scheduler-1.6.2.dist-info/direct_url.json",
  "lib/python3.8/site-packages/adaptive_scheduler/__init__.py",
  "lib/python3.8/site-packages/adaptive_scheduler/_mock_scheduler.py",
  "lib/python3.8/site-packages/adaptive_scheduler/_static_version.py",
  "lib/python3.8/site-packages/adaptive_scheduler/_version.py",
  "lib/python3.8/site-packages/adaptive_scheduler/client_support.py",
  "lib/python3.8/site-packages/adaptive_scheduler/run_script.py.j2",
  "lib/python3.8/site-packages/adaptive_scheduler/scheduler.py",
  "lib/python3.8/site-packages/adaptive_scheduler/sequence_learner.py",
  "lib/python3.8/site-packages/adaptive_scheduler/server_support.py",
  "lib/python3.8/site-packages/adaptive_scheduler/utils.py",
  "lib/python3.8/site-packages/adaptive_scheduler/widgets.py"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py38h578d9bd_0",
  "build_number": 0,
  "depends": [
   "adaptive >=0.14.1",
   "cloudpickle",
   "dill",
   "ipyparallel",
   "ipywidgets",
   "jinja2",
   "loky",
   "mpi4py",
   "mpich",
   "numpy",
   "pandas",
   "psutil",
   "pyarrow",
   "python >=3.8,<3.9.0a0",
   "python_abi 3.8.* *_cp38",
   "pyzmq",
   "structlog",
   "tinydb",
   "toolz",
   "tqdm"
  ],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "name": "adaptive-scheduler",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1679079469101,
  "version": "1.6.2"
 },
 "metadata_version": 1,
 "name": "adaptive-scheduler",
 "raw_recipe": "{% set name = \"adaptive-scheduler\" %}\n{% set version = \"1.6.2\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/adaptive_scheduler-{{ version }}.tar.gz\n  sha256: b60255287e6d695f6c7c1685f0627ae8e2cf5898b3e89e740c775376b3084ea1\n\nbuild:\n  number: 0\n  skip: true  # [win]\n  skip: true  # [py<38]\n  script: {{ PYTHON }} -m pip install . --no-deps -vv\n\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - adaptive >=0.14.1\n    - cloudpickle\n    - dill\n    - ipyparallel\n    - ipywidgets\n    - jinja2\n    - loky\n    - mpi4py\n    - mpich\n    - numpy\n    - pandas\n    - psutil\n    - pyarrow\n    - pyzmq\n    - structlog\n    - tinydb\n    - toolz\n    - tqdm\n\ntest:\n  imports:\n    - adaptive_scheduler\n\nabout:\n  home: http://github.com/basnijholt/adaptive-scheduler\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE\n  summary: An asynchronous scheduler for Adaptive\n  description: |\n    The Adaptive scheduler solves the following problem, you need to run a few 100 \n    learners and can use >1k cores. `ipyparallel` and `dask.distributed` provide \n    very powerful engines for interactive sessions. However, when you want to \n    connect to >1k cores it starts to struggle. Besides that, on a shared cluster \n    there is often the problem of starting an interactive session with ample space \n    available. Our approach is to schedule a different job for each `\n    adaptive.Learner`. The creation and running of these jobs are managed by `\n    adaptive-scheduler`. This means that your calculation will definitely run, even \n    though the cluster might be fully occupied at the moment. Because of this \n    approach, there is almost no limit to how many cores you want to use. You can \n    either use 10 nodes for 1 job (`learner`) or 1 core for 1 job (`learner`) while \n    scheduling hundreds of jobs. Everything is written such that the computation is \n    maximally local. This means that is one of the jobs crashes, there is no \n    problem and it will automatically schedule a new one and continue the \n    calculation where it left off (because of Adaptive's periodic saving \n    functionality). Even if the central \"job manager\" dies, the jobs will continue \n    to run (although no new jobs will be scheduled.) \n  doc_url: http://adaptive-scheduler.readthedocs.io\n  dev_url: https://github.com/basnijholt/adaptive-scheduler\n\nextra:\n  recipe-maintainers:\n    - basnijholt\n",
 "rendered_recipe": {
  "about": {
   "description": "The Adaptive scheduler solves the following problem, you need to run a few 100\nlearners and can use >1k cores. `ipyparallel` and `dask.distributed` provide\nvery powerful engines for interactive sessions. However, when you want to\nconnect to >1k cores it starts to struggle. Besides that, on a shared cluster\nthere is often the problem of starting an interactive session with ample space\navailable. Our approach is to schedule a different job for each `\nadaptive.Learner`. The creation and running of these jobs are managed by `\nadaptive-scheduler`. This means that your calculation will definitely run, even\nthough the cluster might be fully occupied at the moment. Because of this\napproach, there is almost no limit to how many cores you want to use. You can\neither use 10 nodes for 1 job (`learner`) or 1 core for 1 job (`learner`) while\nscheduling hundreds of jobs. Everything is written such that the computation is\nmaximally local. This means that is one of the jobs crashes, there is no\nproblem and it will automatically schedule a new one and continue the\ncalculation where it left off (because of Adaptive's periodic saving\nfunctionality). Even if the central \"job manager\" dies, the jobs will continue\nto run (although no new jobs will be scheduled.)\n",
   "dev_url": "https://github.com/basnijholt/adaptive-scheduler",
   "doc_url": "http://adaptive-scheduler.readthedocs.io",
   "home": "http://github.com/basnijholt/adaptive-scheduler",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE",
   "summary": "An asynchronous scheduler for Adaptive"
  },
  "build": {
   "number": "0",
   "script": "/home/conda/feedstock_root/build_artifacts/adaptive-scheduler_1679079337187/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/bin/python -m pip install . --no-deps -vv",
   "string": "py38h578d9bd_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "basnijholt"
   ]
  },
  "package": {
   "name": "adaptive-scheduler",
   "version": "1.6.2"
  },
  "requirements": {
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 2_gnu",
    "bzip2 1.0.8 h7f98852_4",
    "ca-certificates 2022.12.7 ha878542_0",
    "ld_impl_linux-64 2.40 h41732ed_0",
    "libffi 3.4.2 h7f98852_5",
    "libgcc-ng 12.2.0 h65d4601_19",
    "libgomp 12.2.0 h65d4601_19",
    "libnsl 2.0.0 h7f98852_0",
    "libsqlite 3.40.0 h753d276_0",
    "libuuid 2.32.1 h7f98852_1000",
    "libzlib 1.2.13 h166bdaf_4",
    "ncurses 6.3 h27087fc_1",
    "openssl 3.1.0 h0b41bf4_0",
    "pip 23.0.1 pyhd8ed1ab_0",
    "python 3.8.16 he550d4f_1_cpython",
    "readline 8.1.2 h0f457ee_0",
    "setuptools 67.6.0 pyhd8ed1ab_0",
    "tk 8.6.12 h27826a3_0",
    "wheel 0.40.0 pyhd8ed1ab_0",
    "xz 5.2.6 h166bdaf_0"
   ],
   "run": [
    "adaptive >=0.14.1",
    "cloudpickle",
    "dill",
    "ipyparallel",
    "ipywidgets",
    "jinja2",
    "loky",
    "mpi4py",
    "mpich",
    "numpy",
    "pandas",
    "psutil",
    "pyarrow",
    "python >=3.8,<3.9.0a0",
    "python_abi 3.8.* *_cp38",
    "pyzmq",
    "structlog",
    "tinydb",
    "toolz",
    "tqdm"
   ]
  },
  "source": {
   "sha256": "b60255287e6d695f6c7c1685f0627ae8e2cf5898b3e89e740c775376b3084ea1",
   "url": "https://pypi.io/packages/source/a/adaptive-scheduler/adaptive_scheduler-1.6.2.tar.gz"
  },
  "test": {
   "imports": [
    "adaptive_scheduler"
   ]
  }
 },
 "version": "1.6.2"
}