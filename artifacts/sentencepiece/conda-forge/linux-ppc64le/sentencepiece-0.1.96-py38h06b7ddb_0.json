{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.21.8",
  "conda_private": false,
  "conda_version": "4.11.0",
  "description": "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for\nNeural Network-based text generation systems where the vocabulary size is\npredetermined prior to the neural model training.\n\nSentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n[[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\nlanguage model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\nextension of direct training from raw sentences. SentencePiece allows us to\nmake a purely end-to-end system that does not depend on language-specific\npre/postprocessing.\n",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "setu4993",
    "rluria14",
    "ndmaxar",
    "oblute",
    "h-vetinari"
   ]
  },
  "home": "https://github.com/google/sentencepiece/",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "license_file": "LICENSE",
  "root_pkgs": [
   "tzdata 2021e he74cb21_0",
   "commonmark 0.9.1 py_0",
   "bzip2 1.0.8 h4e0d66e_4",
   "krb5 1.19.2 haf43566_3",
   "six 1.16.0 pyh6c4a22f_0",
   "colorama 0.4.4 pyh9f0ad1d_0",
   "wcwidth 0.2.5 pyh9f0ad1d_2",
   "c-ares 1.18.1 h4e0d66e_0",
   "openssl 1.1.1l h4e0d66e_0",
   "pysocks 1.7.1 py39hc1b9086_4",
   "pkginfo 1.8.2 pyhd8ed1ab_0",
   "libxml2 2.9.12 h1876533_1",
   "expat 2.4.4 h3b9df90_0",
   "pcre2 10.37 h32277c3_0",
   "libgomp 11.2.0 h7698a5e_12",
   "sqlite 3.37.0 h4e2196e_0",
   "patchelf 0.14.3 hea85c5d_0",
   "charset-normalizer 2.0.11 pyhd8ed1ab_0",
   "lzo 2.10 h6eb9509_1000",
   "libev 4.33 h6eb9509_1",
   "anaconda-client 1.8.0 pyhd8ed1ab_0",
   "psutil 5.9.0 py39ha810350_0",
   "zlib 1.2.11 h339bb43_1013",
   "typing_extensions 4.0.1 pyha770c72_0",
   "markupsafe 2.0.1 py39ha810350_1",
   "pybind11-abi 4 hd8ed1ab_3",
   "attrs 21.4.0 pyhd8ed1ab_0",
   "beautifulsoup4 4.10.0 pyha770c72_0",
   "liblief 0.11.5 h3b9df90_1",
   "reproc 14.2.3 h4e0d66e_0",
   "libffi 3.4.2 h4e0d66e_5",
   "ruamel.yaml.clib 0.2.6 py39hf1a8857_0",
   "python-libarchive-c 4.0 py39h0b1cf3c_0",
   "_openmp_mutex 4.5 1_gnu",
   "json5 0.9.5 pyh9f0ad1d_0",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "ncurses 6.3 h3b9df90_0",
   "pycosat 0.6.3 py39ha810350_1009",
   "importlib-metadata 4.10.1 py39hc1b9086_0",
   "patch 2.7.6 h4e0d66e_1002",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "libnghttp2 1.46.0 h42039ad_0",
   "backports 1.0 py_2",
   "libgcc-ng 11.2.0 h7698a5e_12",
   "pip 22.0.3 pyhd8ed1ab_0",
   "libzlib 1.2.11 h339bb43_1013",
   "ruamel.yaml 0.17.19 py39hf1a8857_0",
   "wheel 0.37.1 pyhd8ed1ab_0",
   "conda-build 3.21.8 py39h0b1cf3c_0",
   "cryptography 36.0.1 py39hbd557f1_0",
   "ca-certificates 2021.10.8 h1084571_0",
   "dataclasses 0.8 pyhc8e2a94_3",
   "curl 7.81.0 he415e40_0",
   "reproc-cpp 14.2.3 h3b9df90_0",
   "su-exec 0.2 h6eb9509_1002",
   "prompt_toolkit 3.0.26 hd8ed1ab_0",
   "lz4-c 1.9.3 h3b9df90_1",
   "readline 8.1 h5c45dff_0",
   "tini 0.19.0 h4e0d66e_0",
   "icu 69.1 h3b4ca64_0",
   "pytz 2021.3 pyhd8ed1ab_0",
   "prompt-toolkit 3.0.26 pyha770c72_0",
   "clyent 1.2.2 py_1",
   "glob2 0.7 py_0",
   "libedit 3.1.20191231 h41a240f_2",
   "xz 5.2.5 h6eb9509_1",
   "libsolv 0.7.19 h690f14c_5",
   "py-lief 0.11.5 py39h4c72827_1",
   "jinja2 3.0.3 pyhd8ed1ab_0",
   "pyyaml 6.0 py39ha810350_3",
   "ipython_genutils 0.2.0 py_1",
   "inotify_simple 1.3.5 pyha770c72_3",
   "libiconv 1.16 h6eb9509_0",
   "python_abi 3.9 2_cp39",
   "_libgcc_mutex 0.1 conda_forge",
   "pyrsistent 0.18.1 py39ha810350_0",
   "rich 11.1.0 pyhd8ed1ab_0",
   "conda-package-handling 1.7.3 py39ha810350_1",
   "tqdm 4.62.3 pyhd8ed1ab_0",
   "conda 4.11.0 py39h0b1cf3c_0",
   "idna 3.3 pyhd8ed1ab_0",
   "urllib3 1.26.8 pyhd8ed1ab_1",
   "python 3.9.10 h1456e17_2_cpython",
   "tk 8.6.11 h41c6715_1",
   "git 2.35.0 pl5321h29e2a4d_0",
   "soupsieve 2.3.1 pyhd8ed1ab_0",
   "future 0.18.2 py39hc1b9086_4",
   "requests 2.27.1 pyhd8ed1ab_0",
   "pygments 2.11.2 pyhd8ed1ab_0",
   "libnsl 2.0.0 h4e0d66e_0",
   "traitlets 5.1.1 pyhd8ed1ab_0",
   "ruamel_yaml 0.15.80 py39ha810350_1006",
   "libstdcxx-ng 11.2.0 habdf983_12",
   "jsonschema 4.4.0 pyhd8ed1ab_0",
   "zipp 3.7.0 pyhd8ed1ab_1",
   "certifi 2021.10.8 py39hc1b9086_1",
   "brotlipy 0.7.0 py39ha810350_1003",
   "joblib 1.1.0 pyhd8ed1ab_0",
   "perl 5.32.1 1_h4e0d66e_perl5",
   "pyopenssl 22.0.0 pyhd8ed1ab_0",
   "zstd 1.5.1 h65c4b1a_0",
   "gettext 0.19.8.1 h6603d1e_1008",
   "libcurl 7.81.0 he415e40_0",
   "setuptools 60.7.1 py39hc1b9086_0",
   "libuuid 2.32.1 h4e0d66e_1000",
   "yaml 0.2.5 h4e0d66e_2",
   "pycparser 2.21 pyhd8ed1ab_0",
   "cffi 1.15.0 py39h7bf629d_0",
   "chardet 4.0.0 py39hc1b9086_2",
   "ripgrep 13.0.0 ha57a3a6_1",
   "importlib_resources 5.4.0 pyhd8ed1ab_0",
   "libarchive 3.5.2 h3281d6a_1",
   "ld_impl_linux-ppc64le 2.36.1 ha35d02b_2",
   "filelock 3.4.2 pyhd8ed1ab_1",
   "libssh2 1.10.0 ha5a9321_2",
   "yaml-cpp 0.6.3 hb209c28_4",
   "nbformat 5.1.3 pyhd8ed1ab_0",
   "jupyter_core 4.9.1 py39h0b1cf3c_1",
   "click 8.0.3 py39hc1b9086_1",
   "oniguruma 6.9.7.1 h4e0d66e_0",
   "conda-env 2.6.0 1",
   "watchgod 0.7 pyhd8ed1ab_0",
   "jq 1.6 h339bb43_1000",
   "libmambapy 0.19.1 py39h038a47e_0",
   "mamba 0.19.1 py39h3651b5a_0",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "boa 0.8.2 pyha770c72_0",
   "conda-forge-ci-setup 3.18.1 py39ha7e1dda_0",
   "libmamba 0.19.1 hd0e580a_0"
  ],
  "summary": "Unsupervised text tokenizer for Neural Network-based text generation.",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos7",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "cxx_compiler_version": "9",
  "docker_image": "quay.io/condaforge/linux-anvil-ppc64le",
  "extend_keys": [
   "extend_keys",
   "ignore_build_only_deps",
   "pin_run_as_build",
   "ignore_version"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "python",
   "numpy"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.8.* *_cpython",
  "r_base": "3.5",
  "target_platform": "linux-ppc64le"
 },
 "files": [
  "bin/spm_decode",
  "bin/spm_encode",
  "bin/spm_export_vocab",
  "bin/spm_normalize",
  "bin/spm_train",
  "include/sentencepiece_processor.h",
  "include/sentencepiece_trainer.h",
  "lib/libsentencepiece.a",
  "lib/libsentencepiece.so",
  "lib/libsentencepiece.so.0",
  "lib/libsentencepiece.so.0.0.0",
  "lib/libsentencepiece_train.a",
  "lib/libsentencepiece_train.so",
  "lib/libsentencepiece_train.so.0",
  "lib/libsentencepiece_train.so.0.0.0",
  "lib/pkgconfig/sentencepiece.pc",
  "lib/python3.8/site-packages/sentencepiece-0.1.96-py3.8-linux-ppc64le.egg-info/PKG-INFO",
  "lib/python3.8/site-packages/sentencepiece-0.1.96-py3.8-linux-ppc64le.egg-info/not-zip-safe",
  "lib/python3.8/site-packages/sentencepiece/__init__.py",
  "lib/python3.8/site-packages/sentencepiece/_sentencepiece.cpython-38-powerpc64le-linux-gnu.so",
  "lib/python3.8/site-packages/sentencepiece/_sentencepiece.py",
  "lib/python3.8/site-packages/sentencepiece/sentencepiece_model_pb2.py",
  "lib/python3.8/site-packages/sentencepiece/sentencepiece_pb2.py"
 ],
 "index": {
  "arch": "ppc64le",
  "build": "py38h06b7ddb_0",
  "build_number": 0,
  "depends": [
   "libgcc-ng >=9.4.0",
   "libstdcxx-ng >=9.4.0",
   "python >=3.8,<3.9.0a0",
   "python_abi 3.8.* *_cp38"
  ],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "name": "sentencepiece",
  "platform": "linux",
  "subdir": "linux-ppc64le",
  "timestamp": 1644566439804,
  "version": "0.1.96"
 },
 "metadata_version": 1,
 "name": "sentencepiece",
 "raw_recipe": "{% set version = \"0.1.96\" %}\n\npackage:\n  name: sentencepiece\n  version: {{ version }}\n\nsource:\n  url: https://github.com/google/sentencepiece/archive/v{{ version }}.tar.gz\n  sha256: 5198f31c3bb25e685e9e68355a3bf67a1db23c9e8bdccc33dc015f496a44df7a\n\nbuild:\n  number: 0\n\nrequirements:\n  build:\n    - python                                 # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - cmake\n    - {{ compiler('cxx') }}\n    - gperftools  # [unix]\n    - make\n    - pkg-config\n  host:\n    - pip\n    - python\n  run:\n    - python\n\ntest:\n  imports:\n    - sentencepiece\n  requires:\n    - pip\n    - pytest\n  source_files:\n    - python/test\n    - data\n  commands:\n    - pip check\n    - spm_export_vocab --help  # [linux]\n    - spm_normalize --help     # [linux]\n    # upstream test suite expects to be run from PKG_ROOT/python\n    - cd python && pytest test\n\nabout:\n  home: \"https://github.com/google/sentencepiece/\"\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n  summary: Unsupervised text tokenizer for Neural Network-based text generation.\n  description: |\n    SentencePiece is an unsupervised text tokenizer and detokenizer mainly for\n    Neural Network-based text generation systems where the vocabulary size is\n    predetermined prior to the neural model training.\n\n    SentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n    [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\n    language model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\n    extension of direct training from raw sentences. SentencePiece allows us to\n    make a purely end-to-end system that does not depend on language-specific\n    pre/postprocessing.\n\nextra:\n  recipe-maintainers:\n    - setu4993\n    - rluria14\n    - ndmaxar\n    - oblute\n    - h-vetinari\n",
 "rendered_recipe": {
  "about": {
   "description": "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for\nNeural Network-based text generation systems where the vocabulary size is\npredetermined prior to the neural model training.\n\nSentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n[[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\nlanguage model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\nextension of direct training from raw sentences. SentencePiece allows us to\nmake a purely end-to-end system that does not depend on language-specific\npre/postprocessing.\n",
   "home": "https://github.com/google/sentencepiece/",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "LICENSE",
   "summary": "Unsupervised text tokenizer for Neural Network-based text generation."
  },
  "build": {
   "number": "0",
   "string": "py38h06b7ddb_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "h-vetinari",
    "ndmaxar",
    "oblute",
    "rluria14",
    "setu4993"
   ]
  },
  "package": {
   "name": "sentencepiece",
   "version": "0.1.96"
  },
  "requirements": {
   "build": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "binutils_impl_linux-ppc64le 2.36.1 h5836da8_2",
    "binutils_linux-ppc64le 2.36 he035471_4",
    "bzip2 1.0.8 h4e0d66e_4",
    "c-ares 1.18.1 h4e0d66e_0",
    "ca-certificates 2021.10.8 h1084571_0",
    "cmake 3.21.3 hadba709_0",
    "expat 2.4.4 h3b9df90_0",
    "gcc_impl_linux-ppc64le 9.4.0 hcbd312b_12",
    "gcc_linux-ppc64le 9.4.0 h2449294_4",
    "gperftools 2.9.1 hf4752a0_1",
    "gxx_impl_linux-ppc64le 9.4.0 hcbd312b_12",
    "gxx_linux-ppc64le 9.4.0 h64afa7a_4",
    "kernel-headers_linux-ppc64le 3.10.0 h23d7e6c_13",
    "krb5 1.19.2 hf9a8087_3",
    "ld_impl_linux-ppc64le 2.36.1 ha35d02b_2",
    "libcurl 7.81.0 h3643067_0",
    "libedit 3.1.20191231 h41a240f_2",
    "libev 4.33 h6eb9509_1",
    "libgcc-devel_linux-ppc64le 9.4.0 he021ec0_12",
    "libgcc-ng 11.2.0 h7698a5e_12",
    "libgomp 11.2.0 h7698a5e_12",
    "libnghttp2 1.46.0 h66fdf1b_0",
    "libsanitizer 9.4.0 h106b142_12",
    "libssh2 1.10.0 he881182_2",
    "libstdcxx-devel_linux-ppc64le 9.4.0 he021ec0_12",
    "libstdcxx-ng 11.2.0 habdf983_12",
    "libunwind 1.6.2 h3b9df90_0",
    "libuv 1.43.0 h4e0d66e_0",
    "libzlib 1.2.11 h339bb43_1013",
    "lz4-c 1.9.3 h3b9df90_1",
    "make 4.3 hf817498_1",
    "ncurses 6.3 h3b9df90_0",
    "openssl 3.0.0 h4e0d66e_2",
    "perl 5.32.1 1_h4e0d66e_perl5",
    "pkg-config 0.29.2 h339bb43_1008",
    "rhash 1.4.1 h4e0d66e_0",
    "sysroot_linux-ppc64le 2.17 h395ec9b_13",
    "tk 8.6.11 h41c6715_1",
    "xz 5.2.5 h6eb9509_1",
    "zlib 1.2.11 h339bb43_1013",
    "zstd 1.5.1 h65c4b1a_0"
   ],
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "ca-certificates 2021.10.8 h1084571_0",
    "ld_impl_linux-ppc64le 2.36.1 ha35d02b_2",
    "libffi 3.4.2 h4e0d66e_5",
    "libgcc-ng 11.2.0 h7698a5e_12",
    "libgomp 11.2.0 h7698a5e_12",
    "libnsl 2.0.0 h4e0d66e_0",
    "libstdcxx-ng 11.2.0 habdf983_12",
    "libzlib 1.2.11 h339bb43_1013",
    "ncurses 6.3 h3b9df90_0",
    "openssl 3.0.0 h4e0d66e_2",
    "pip 22.0.3 pyhd8ed1ab_0",
    "python 3.8.12 hbedf6d4_3_cpython",
    "python_abi 3.8 2_cp38",
    "readline 8.1 h5c45dff_0",
    "setuptools 60.8.1 py38hf8b3453_0",
    "sqlite 3.37.0 h4e2196e_0",
    "tk 8.6.11 h41c6715_1",
    "wheel 0.37.1 pyhd8ed1ab_0",
    "xz 5.2.5 h6eb9509_1",
    "zlib 1.2.11 h339bb43_1013"
   ],
   "run": [
    "libgcc-ng >=9.4.0",
    "libstdcxx-ng >=9.4.0",
    "python >=3.8,<3.9.0a0",
    "python_abi 3.8.* *_cp38"
   ]
  },
  "source": {
   "sha256": "5198f31c3bb25e685e9e68355a3bf67a1db23c9e8bdccc33dc015f496a44df7a",
   "url": "https://github.com/google/sentencepiece/archive/v0.1.96.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "spm_export_vocab --help",
    "spm_normalize --help",
    "cd python && pytest test"
   ],
   "imports": [
    "sentencepiece"
   ],
   "requires": [
    "pip",
    "pytest"
   ],
   "source_files": [
    "data",
    "python/test"
   ]
  }
 },
 "version": "0.1.96"
}