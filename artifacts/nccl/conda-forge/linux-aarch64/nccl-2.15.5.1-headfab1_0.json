{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.24.0",
  "conda_version": "23.3.1",
  "description": "The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\nand multi-node collective communication primitives that are performance\noptimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\nall-reduce, broadcast, reduce, reduce-scatter, that are optimized to\nachieve high bandwidth over PCIe and NVLink high-speed interconnect.\n",
  "dev_url": "https://github.com/NVIDIA/nccl",
  "doc_url": "https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "jakirkham",
    "leofang"
   ]
  },
  "home": "https://developer.nvidia.com/nccl",
  "identifiers": [],
  "keywords": [],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "license_file": "LICENSE.txt",
  "root_pkgs": [
   "lzo 2.10 h516909a_1000",
   "joblib 1.2.0 pyhd8ed1ab_0",
   "boa 0.14.0 pyhd8ed1ab_4",
   "anaconda-project 0.11.1 pyhd8ed1ab_0",
   "_openmp_mutex 4.5 2_gnu",
   "importlib-metadata 6.2.0 pyha770c72_0",
   "libffi 3.4.2 h3557bc0_5",
   "libxml2 2.10.3 h430b14f_6",
   "pysocks 1.7.1 pyha2e5f31_6",
   "tk 8.6.12 hd8af866_0",
   "libdeflate 1.18 hb4cce97_0",
   "libwebp-base 1.3.0 hb4cce97_0",
   "urllib3 1.26.15 pyhd8ed1ab_0",
   "libzlib 1.2.13 h4e544f5_4",
   "dataclasses 0.8 pyhc8e2a94_3",
   "libcurl 7.88.1 h6ad7c7a_1",
   "freetype 2.12.1 hbbbf32d_1",
   "tini 0.19.0 h4e544f5_1",
   "tomli 2.0.1 pyhd8ed1ab_0",
   "xz 5.2.6 h9cdd2b7_0",
   "tornado 6.2 py310hdc54845_1",
   "clyent 1.2.2 py_1",
   "prompt_toolkit 3.0.38 hd8ed1ab_0",
   "libarchive 3.6.2 hc81d4a0_0",
   "readline 8.2 h8fc344f_1",
   "pyrsistent 0.19.3 py310h734f5e8_0",
   "sniffio 1.3.0 pyhd8ed1ab_0",
   "defusedxml 0.7.1 pyhd8ed1ab_0",
   "boltons 23.0.0 pyhd8ed1ab_0",
   "jsonpointer 2.0 py_0",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "cffi 1.15.1 py310hf0c4615_3",
   "pip 23.0.1 pyhd8ed1ab_0",
   "typing-extensions 4.5.0 hd8ed1ab_0",
   "idna 3.4 pyhd8ed1ab_0",
   "tqdm 4.65.0 pyhd8ed1ab_1",
   "py-lief 0.12.3 py310h130cc07_0",
   "filelock 3.11.0 pyhd8ed1ab_0",
   "certifi 2022.12.7 pyhd8ed1ab_0",
   "libgcc-ng 12.2.0 h607ecd0_19",
   "conda-pack 0.7.0 pyh6c4a22f_0",
   "rich 13.3.3 pyhd8ed1ab_0",
   "libgomp 12.2.0 h607ecd0_19",
   "importlib_resources 5.12.0 pyhd8ed1ab_0",
   "keyutils 1.6.1 h4e544f5_0",
   "traitlets 5.9.0 pyhd8ed1ab_0",
   "prompt-toolkit 3.0.38 pyha770c72_0",
   "beautifulsoup4 4.12.2 pyha770c72_0",
   "libmambapy 1.4.2 py310hbc2a718_0",
   "pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0",
   "libnghttp2 1.52.0 h250e5c5_0",
   "psutil 5.9.4 py310h761cc84_0",
   "pygments 2.14.0 pyhd8ed1ab_0",
   "pycosat 0.6.4 py310h761cc84_1",
   "curl 7.88.1 h6ad7c7a_1",
   "libjpeg-turbo 2.1.5.1 hb4cce97_0",
   "python 3.10.10 ha43d526_0_cpython",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "chardet 5.1.0 py310hbbe02a8_0",
   "tzdata 2023c h71feb2d_0",
   "python_abi 3.10 3_cp310",
   "patchelf 0.17.2 h884eca8_0",
   "xorg-libxdmcp 1.1.3 h3557bc0_0",
   "pkginfo 1.9.6 pyhd8ed1ab_0",
   "ruamel_yaml 0.15.80 py310h761cc84_1008",
   "bzip2 1.0.8 hf897c2e_4",
   "pyyaml 6.0 py310h761cc84_5",
   "libmamba 1.4.2 h4a4fd89_0",
   "expat 2.5.0 hd600fc2_1",
   "liblief 0.12.3 h4de3ea5_0",
   "git 2.40.0 pl5321h7e2208b_1",
   "krb5 1.20.1 h113d92e_0",
   "backports 1.0 pyhd8ed1ab_3",
   "yaml-cpp 0.7.0 h4de3ea5_2",
   "libexpat 2.5.0 hd600fc2_1",
   "requests 2.28.2 pyhd8ed1ab_1",
   "gettext 0.21.1 ha18d298_0",
   "pcre2 10.40 he7b27c6_0",
   "mdurl 0.1.0 pyhd8ed1ab_0",
   "reproc-cpp 14.2.4 hd600fc2_0",
   "reproc 14.2.4 hb4cce97_0",
   "libssh2 1.10.0 he5a64b1_3",
   "fmt 9.1.0 hdd96247_0",
   "jsonpatch 1.32 pyhd8ed1ab_0",
   "conda-package-streaming 0.7.0 pyhd8ed1ab_1",
   "wcwidth 0.2.6 pyhd8ed1ab_0",
   "pluggy 1.0.0 pyhd8ed1ab_5",
   "jinja2 3.1.2 pyhd8ed1ab_1",
   "libuuid 2.38.1 hb4cce97_0",
   "zipp 3.15.0 pyhd8ed1ab_0",
   "openssl 3.1.0 hb4cce97_0",
   "markdown-it-py 2.2.0 pyhd8ed1ab_0",
   "anaconda-client 1.11.1 pyhd8ed1ab_1",
   "soupsieve 2.3.2.post1 pyhd8ed1ab_0",
   "libev 4.33 h516909a_1",
   "libxcb 1.13 h3557bc0_1004",
   "ripgrep 13.0.0 hc770f70_2",
   "brotlipy 0.7.0 py310h761cc84_1005",
   "ruamel.yaml.clib 0.2.7 py310hb89b984_1",
   "python-libarchive-c 4.0 py310h4c7bcd0_2",
   "wheel 0.40.0 pyhd8ed1ab_0",
   "libstdcxx-ng 12.2.0 hc13a102_19",
   "pytz 2023.3 pyhd8ed1ab_0",
   "zstd 1.5.2 h44f6412_6",
   "lcms2 2.15 h3e0bdec_1",
   "pycparser 2.21 pyhd8ed1ab_0",
   "yaml 0.2.5 hf897c2e_2",
   "libedit 3.1.20191231 he28a2e2_2",
   "su-exec 0.2 h4e544f5_1003",
   "charset-normalizer 3.1.0 pyhd8ed1ab_0",
   "mamba 1.4.2 py310hcbdc16a_0",
   "typing_extensions 4.5.0 pyha770c72_0",
   "ncurses 6.3 headf329_1",
   "libsolv 0.7.23 h3cb9bc8_0",
   "jsonschema 4.17.3 pyhd8ed1ab_0",
   "openjpeg 2.5.0 h9508984_2",
   "pillow 9.5.0 py310hcf0f7da_0",
   "libsqlite 3.40.0 hf9034f9_0",
   "cryptography 40.0.1 py310he4ba0b1_0",
   "jupyter_core 5.3.0 py310h4c7bcd0_0",
   "libpng 1.6.39 hf9034f9_0",
   "packaging 23.0 pyhd8ed1ab_0",
   "markupsafe 2.1.2 py310h734f5e8_0",
   "perl 5.32.1 2_hf897c2e_perl5",
   "libtiff 4.5.0 h536c0eb_6",
   "conda 23.3.1 py310h4c7bcd0_0",
   "c-ares 1.18.1 hf897c2e_0",
   "pyopenssl 23.1.1 pyhd8ed1ab_0",
   "ruamel.yaml 0.17.21 py310hb89b984_3",
   "python-fastjsonschema 2.16.3 pyhd8ed1ab_0",
   "ca-certificates 2022.12.7 h4fd8a4c_0",
   "setuptools 65.6.3 pyhd8ed1ab_0",
   "libnsl 2.0.0 hf897c2e_0",
   "pthread-stubs 0.4 hb9de7d4_1001",
   "zstandard 0.19.0 py310hde4b81c_1",
   "icu 72.1 hcf00150_0",
   "lz4-c 1.9.4 hd600fc2_0",
   "xorg-libxau 1.0.9 h3557bc0_0",
   "toolz 0.12.0 pyhd8ed1ab_0",
   "anyio 3.6.2 pyhd8ed1ab_0",
   "patch 2.7.6 hf897c2e_1002",
   "watchgod 0.8.2 pyhd8ed1ab_0",
   "platformdirs 3.2.0 pyhd8ed1ab_0",
   "libiconv 1.17 h9cdd2b7_0",
   "attrs 22.2.0 pyh71513ae_0",
   "ld_impl_linux-aarch64 2.40 h2d8c526_0",
   "pybind11-abi 4 hd8ed1ab_3",
   "six 1.16.0 pyh6c4a22f_0",
   "json5 0.9.5 pyh9f0ad1d_0",
   "glob2 0.7 py_0",
   "colorama 0.4.6 pyhd8ed1ab_0",
   "conda-package-handling 2.0.2 pyh38be061_0",
   "nbformat 5.8.0 pyhd8ed1ab_0",
   "lerc 4.0.0 h4de3ea5_0",
   "conda-env 2.6.0 1",
   "oniguruma 6.9.8 h4e544f5_0",
   "jq 1.6 hb9de7d4_1000",
   "click 8.1.3 unix_pyhd8ed1ab_2",
   "conda-build 3.24.0 py310h4c7bcd0_1",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "conda-forge-ci-setup 3.29.1 py310hf7ba518_100"
  ],
  "summary": "Optimized primitives for collective multi-GPU communication",
  "tags": []
 },
 "conda_build_config": {
  "BUILD": "aarch64-conda_cos7-linux-gnu",
  "CI": "azure",
  "arm_variant_type": "sbsa",
  "c_compiler": "gcc",
  "c_compiler_version": "9",
  "cdt_arch": "aarch64",
  "cdt_name": "cos7",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cuda_compiler": "nvcc",
  "cuda_compiler_version": "11.1",
  "cudnn": "undefined",
  "cxx_compiler": "gxx",
  "cxx_compiler_version": "9",
  "docker_image": "quay.io/condaforge/linux-anvil-aarch64-cuda:11.1",
  "extend_keys": [
   "pin_run_as_build",
   "ignore_build_only_deps",
   "ignore_version",
   "extend_keys"
  ],
  "fortran_compiler": "gfortran",
  "fortran_compiler_version": "9",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "numpy": "1.21",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.10",
  "r_base": "3.5",
  "target_platform": "linux-aarch64",
  "zip_keys": [
   [
    "c_compiler_version",
    "cxx_compiler_version",
    "cuda_compiler_version",
    "cdt_name",
    "docker_image"
   ]
  ]
 },
 "conda_pkg_format": "2",
 "files": [
  "include/nccl.h",
  "include/nccl_net.h",
  "lib/libnccl.so",
  "lib/libnccl.so.2",
  "lib/libnccl.so.2.15.5",
  "lib/pkgconfig/nccl.pc"
 ],
 "index": {
  "arch": "aarch64",
  "build": "headfab1_0",
  "build_number": 0,
  "depends": [
   "__glibc >=2.17",
   "cudatoolkit 11.1|11.1.*",
   "libgcc-ng >=12",
   "libstdcxx-ng >=12"
  ],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "name": "nccl",
  "platform": "linux",
  "subdir": "linux-aarch64",
  "timestamp": 1681417522310,
  "version": "2.15.5.1"
 },
 "metadata_version": 1,
 "name": "nccl",
 "raw_recipe": "{% set name = \"nccl\" %}\n{% set version = \"2.15.5-1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version|replace(\"-\", \".\") }}\n\nsource:\n  url: https://github.com/NVIDIA/nccl/archive/v{{ version }}.tar.gz\n  sha256: f4ac3c74d469c9cd718f82e1477759785db9b9f8cc9d9ecc103485805b8394a3\n\nbuild:\n  number: 0\n  skip: true  # [(not linux) or cuda_compiler_version in (undefined, \"None\")]\n  run_exports:\n    # xref: https://github.com/NVIDIA/nccl/issues/218\n    - {{ pin_subpackage(name, max_pin=\"x\") }}\n  script_env:\n    # for some reason /usr/local/cuda is not added to $PATH in ppc64le's docker image\n    - CUDA_HOME  # [ppc64le or aarch64]\n\nrequirements:\n  build:\n    - {{ compiler(\"c\") }}\n    - {{ compiler(\"cxx\") }}\n    - {{ compiler(\"cuda\") }}\n    - make\n\ntest:\n  commands:\n    - test -f \"${PREFIX}/include/nccl.h\"\n    - test -f \"${PREFIX}/lib/libnccl.so\"\n    - test ! -f \"${PREFIX}/lib/libnccl_static.a\"\n\nabout:\n  home: https://developer.nvidia.com/nccl\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE.txt\n  summary: Optimized primitives for collective multi-GPU communication\n\n  description: |\n    The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\n    and multi-node collective communication primitives that are performance\n    optimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\n    all-reduce, broadcast, reduce, reduce-scatter, that are optimized to\n    achieve high bandwidth over PCIe and NVLink high-speed interconnect.\n\n  doc_url: https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html\n  dev_url: https://github.com/NVIDIA/nccl\n\nextra:\n  recipe-maintainers:\n    - jakirkham\n    - leofang\n",
 "rendered_recipe": {
  "about": {
   "description": "The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\nand multi-node collective communication primitives that are performance\noptimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\nall-reduce, broadcast, reduce, reduce-scatter, that are optimized to\nachieve high bandwidth over PCIe and NVLink high-speed interconnect.\n",
   "dev_url": "https://github.com/NVIDIA/nccl",
   "doc_url": "https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html",
   "home": "https://developer.nvidia.com/nccl",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE.txt",
   "summary": "Optimized primitives for collective multi-GPU communication"
  },
  "build": {
   "number": "0",
   "run_exports": [
    "nccl >=2.15.5.1,<3.0a0"
   ],
   "script_env": [
    "CUDA_HOME"
   ],
   "string": "headfab1_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "jakirkham",
    "leofang"
   ]
  },
  "package": {
   "name": "nccl",
   "version": "2.15.5.1"
  },
  "requirements": {
   "build": [
    "_openmp_mutex 4.5 2_gnu",
    "binutils_impl_linux-aarch64 2.39 h48546ad_1",
    "binutils_linux-aarch64 2.39 h489c705_12",
    "gcc_impl_linux-aarch64 9.5.0 h0c0692e_19",
    "gcc_linux-aarch64 9.5.0 hf6054ea_12",
    "gxx_impl_linux-aarch64 9.5.0 h0c0692e_19",
    "gxx_linux-aarch64 9.5.0 he16ab35_12",
    "kernel-headers_linux-aarch64 4.18.0 h5b4a56d_13",
    "ld_impl_linux-aarch64 2.39 h16cd69b_1",
    "libgcc-devel_linux-aarch64 9.5.0 h30ec8c9_19",
    "libgcc-ng 12.2.0 h607ecd0_19",
    "libgomp 12.2.0 h607ecd0_19",
    "libsanitizer 9.5.0 h3eeb643_19",
    "libstdcxx-devel_linux-aarch64 9.5.0 h30ec8c9_19",
    "libstdcxx-ng 12.2.0 hc13a102_19",
    "make 4.3 h309ac5b_1",
    "nvcc_linux-aarch64 11.1 ha9e409f_22",
    "sed 4.8 ha0d5d3d_0",
    "sysroot_linux-aarch64 2.17 h43d7e78_13"
   ],
   "host": [
    "_openmp_mutex 4.5 2_gnu",
    "cudatoolkit 11.1.1 h3730f35_11",
    "libgcc-ng 12.2.0 h607ecd0_19",
    "libgomp 12.2.0 h607ecd0_19",
    "libstdcxx-ng 12.2.0 hc13a102_19"
   ],
   "run": [
    "__glibc >=2.17",
    "cudatoolkit 11.1|11.1.*",
    "libgcc-ng >=12",
    "libstdcxx-ng >=12"
   ]
  },
  "source": {
   "sha256": "f4ac3c74d469c9cd718f82e1477759785db9b9f8cc9d9ecc103485805b8394a3",
   "url": "https://github.com/NVIDIA/nccl/archive/v2.15.5-1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f \"${PREFIX}/include/nccl.h\"",
    "test -f \"${PREFIX}/lib/libnccl.so\"",
    "test ! -f \"${PREFIX}/lib/libnccl_static.a\""
   ]
  }
 },
 "version": "2.15.5.1"
}